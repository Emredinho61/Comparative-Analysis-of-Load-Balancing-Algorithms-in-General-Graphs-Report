\chapter{Algorithms and Concepts}\label{chap:background}
\input{pseudoalgorithms.tex/DAB}
\input{pseudoalgorithms.tex/PPS}
Simulations in this project were carried out with a network size of up to $2^{14}$ nodes. Accordingly, a simulation tool was required that could cope with such a network size for different topologies (also topologies with high-connectivity). PeerSim is a simulation tool for Java, which fulfils precisely these requirements, which is why we chose it. With PeerSim, you can choose between two simulation models. One is the cycle-driven model and the other is the event-driven model We chose the former to compute the simulations for both algorithms, since both algorithms work in rounds. 

\section{Setting}
Each simulation is run for 50 rounds. The continuous versions of the algorithms are chosen, which means that any load can be transferred across the edges, not just integers. At the beginning of the simulations, the nodes only know information about their loads and a set of their neighbouring nodes. Load transfers can only happen in between rounds. The loads are uniformly distributed values between 0 and 100. For each round of a simulation the mean squared error is computed. Both algorithms are \textit{synchronous}, meaning that the load transfer happens in a constant time). Different topologies are chosen. Simulations are conducted for following topologies:
\begin{itemize}
    \item Complete graph
    \item Star graph
    \item Closed Chain graph
    \item Torus
    \item Regular Ring of Cliques
    \item Lollipop graph
\end{itemize}
\todo{Erklärung warum gerade diese Netzwerktypen}.
For each topology, several simulations with different network sizes are carried out. \todo{Erklärung warum das Sinn macht}.
\todo{tabelle mit den verschiedenen topologien und den Netzwerkgrößen}

\input{Tables/simulationoverview}

\section{Deal-Agreement-Based Algorithm}
Algorithm \ref{alg:DAB} depicts the continous version of the load balancing algorithms proposed in Dinitz et al. paper \cite{dinitz2022localDealAgreementloadBalancing}. This algorithm is divided into three phases, namely the "proposal"-phase, the "deal"-phase and the "summary"-phase. In the "proposal"-phase every node is commanded to propose a \textit{fair} proposal to its neighbor with the minimal load. A proposal of node $u$ to node $v$ is labeled as fair if the transfer $l$ is of amount $l \leq (load_{r}(u)-load_{r}(v))/2$. In the "deal"-phase, the nodes evaluate the proposal and accept the load transfer with the maximal proposing node. The last phase is the "summary"-phase in which the nodes inform their neighbors about their new updated values after the load transfer happened. This approach is a deterministic algorithm, there is no element of random involved. We need to keep this in mind when looking into the simulations later on in chapter \ref{chap:simulations}, since it is more difficult to achieve good results for deterministic approaches then for randomized ones. In addition to that this algorithm is considered a \textit{anytime} algorithm. Algorithms are given this property if they do not worsen the state of the network from one state to the next. We could therefore stop the simulation at any time, regardless of the initial state of the network, and the state of the network would not worsen at any step of the simulation. \todo{Maybe two or three sentenced regarding the time boundaries?}. The algorithm \ref{alg:DAB} defines its output as a "load state with discrepancy at most $\epsilon$ on G". $\epsilon$ is an arbitrarily small bound for the final discrepancy \cite{dinitz2022localDealAgreementloadBalancing}. The discrepancy is the difference between the maximum load and the minimum load of the network. As initial information this algorithm takes in a undirected graph G with all the vertices, edges (interconnection of the vertices) and their respective loads).

\section{Push-Pull-Sum Algorithm}
The Push-Sum protocol as proposed in the paper of Kempe et al.\cite{kempe2003gossipbasedComp} is a load protocol in which nodes chose a random neighbor and push half of their sums and weights to the chosen neighbor. The Push-Pull-Sum algorithm is composed of the Push-Sum and the Pull-Sum algorithm. Upon a push action the caller node sends a pull request to the called node, which results in the called node to send its sum and weight divided by the number of pull requests to the caller node and itself \cite{nugroho2023PushPullSumDataAg}. Consequently, a push operation is a load transfer of the caller node to the called node of $\left(\frac{s_{r}}{2}, \frac{2_{r}}{2}\right)$ and itself. And a pull operation is a load transfer of the called node to the caller nodes of values $\left(\frac{\frac{s_{r}}{2}}{|R|}, \frac{\frac{w_{r}}{2}}{|R|}\right)$ and itself. The implementation of the Push-Pull Sum algorithm is subdivided into three procedures. One of which is the "aggregate" procedure. In the aggregate procedure every node counts the number of ingoing messages, sent by their neighbors to them. One of which is the "aggregate" procedure. The messages sent to a node are aggregated. Following that, the node calculate its sum and weight and computes the average $f_{avg} = \frac{s_{u, r}}{w_{u, r}}$. After the "aggregate" procedure, the "requestdata" procedure is called by the nodes. Here, a random neighbor is chosen and a push operation is executed to the random neighbor and the node u itself. Lastly, the "responsedata" procedure is called. Now, every request that the node received in this round is accumulated in a set $R_{u, r}$. For every request the pull operation is executed to the requesting nodes and the node u itself. All the procedures are called in every round except for the aggregate procedure which is not called in the first round. We can observe that the sum of all weights at any round is equal to the networksize. Unlike the Deal-Agreement-Based algorithm, the Push-Pull-Sum algorithm is no deterministic algorithm, but a randomized algorithm. 